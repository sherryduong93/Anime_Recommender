{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from src.data_funcs import *\n",
    "from src.model_funcs import *\n",
    "from pyspark.sql.functions import explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df = pd.read_csv('data/anime.csv')\n",
    "rating_df = pd.read_csv('data/rating.csv')\n",
    "anime_meta = pd.read_csv('data/AnimeList_meta.csv')\n",
    "users_meta = pd.read_csv('data/UserList_Meta.csv')\n",
    "rating_df = rating_df[rating_df['rating']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_full = full_anime_df(rating_df, anime_df, anime_meta)\n",
    "anime_map = anime_full[['anime_id','name','title_english', 'type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Matrix Factorization Recommenders System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual train_test_split on users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = rating_df.groupby('user_id').count()['rating']\n",
    "user_ids = filt[filt>50].reset_index()['user_id'].values\n",
    "over_df = rating_df[rating_df['user_id'].isin(user_ids)]\n",
    "remaining_df = rating_df[~rating_df['user_id'].isin(user_ids)]\n",
    "over_df.groupby('user_id').count()['rating'].sort_values()\n",
    "y=over_df['user_id']\n",
    "X=over_df.drop(columns=['user_id'])\n",
    "anime_train, anime_test, user_train, user_test = train_test_split(X, y, test_size = 0.20, random_state = 0, stratify=y)\n",
    "train_over_split = pd.concat([anime_train, user_train],axis=1)\n",
    "train = pd.concat([train_over_split, remaining_df], axis=0)\n",
    "test = pd.concat([anime_test, user_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "# y=over_2_df['user_id']\n",
    "# X=over_2_df.drop(columns=['user_id'])\n",
    "# anime_train, anime_test, user_train, user_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify=y)\n",
    "# train_over2_split = pd.concat([anime_train, user_train],axis=1)\n",
    "# train = pd.concat([train_over2_split, remaining_df], axis=0)\n",
    "# test = pd.concat([anime_test, user_test],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Spark ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Convert a Pandas DF to a Spark DF\n",
    "#spark_df = spark.createDataFrame(pandas_df) \n",
    "\n",
    "# Convert a Spark DF to a Pandas DF\n",
    "#pandas_df = spark_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spark = spark.createDataFrame(rating_df)\n",
    "train_spark = spark.createDataFrame(train)\n",
    "test_spark = spark.createDataFrame(test)\n",
    "#Note to self: Add some cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = all_spark.randomSplit([0.8, 0.2], seed=0)\n",
    "train_data, val_data = train_spark.randomSplit([0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[anime_id: bigint, rating: bigint, user_id: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model = ALS(\n",
    "    itemCol='anime_id',\n",
    "    userCol='user_id',\n",
    "    ratingCol='rating',\n",
    "    nonnegative=True,    \n",
    "    maxIter=20,\n",
    "    regParam=0.1,\n",
    "    rank=10) \n",
    "als_model.setColdStartStrategy(\"drop\")\n",
    "\n",
    "recommender = als_model.fit(train_data)\n",
    "\n",
    "os.system(\"say 'Complete'\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = recommender.transform(train_data)\n",
    "preds_val = recommender.transform(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.037179999135848 1.146461759462331\n"
     ]
    }
   ],
   "source": [
    "predstrain_df = preds_train.toPandas()\n",
    "predsval_df = preds_val.toPandas()\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(predstrain_df['rating'],predstrain_df['prediction']))\n",
    "rmse_val = np.sqrt(mean_squared_error(predsval_df['rating'],predsval_df['prediction']))\n",
    "\n",
    "print(rmse_train, rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1343560679695368\n"
     ]
    }
   ],
   "source": [
    "preds_test = recommender.transform(test_spark)\n",
    "predstest_df = preds_test.toPandas()\n",
    "rmse_test = np.sqrt(mean_squared_error(predstest_df['rating'],predstest_df['prediction']))\n",
    "print(rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the latent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=20, features=[0.492931604385376, 0.5206156969070435, 0.646899938583374, 1.0530647039413452, 1.3970526456832886, 0.6397818326950073, 0.7391793727874756, 0.07245408743619919, 1.0065990686416626, 0.028668029233813286])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_features = recommender.itemFactors\n",
    "user_features = recommender.userFactors\n",
    "#10\n",
    "anime_features.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the model with crossvalidation & hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Tuning the model with crossvalidation\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(als_model.rank, [10]) \\\n",
    "#     .addGrid(als_model.maxIter, [20]) \\\n",
    "#     .addGrid(als_model.regParam, [0.1]) \\\n",
    "#     .build()\n",
    "\n",
    "# evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "#                                 predictionCol='prediction')\n",
    "\n",
    "# crossval = CrossValidator(estimator=als_model,\n",
    "#                           estimatorParamMaps=paramGrid,\n",
    "#                           evaluator=evaluator,\n",
    "#                           numFolds=3)\n",
    "\n",
    "# cvModel = crossval.fit(train_data)\n",
    "\n",
    "# preds_cv = cvModel.transform(test_data)\n",
    "# preds_cvdf = preds_cv.toPandas()\n",
    "# rmse_cv = np.sqrt(mean_squared_error(preds_cvdf['rating'],preds_cvdf['prediction']))\n",
    "# pct_mean_cv = round(rmse_cv/(rating_df['rating'].mean())*100,0)\n",
    "# print(f'rmse is {pct_mean_cv}% of mean')\n",
    "# os.system(\"say 'Complete'\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Recommendations For Certain Anime based on what other users that rated the anime highly also liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|anime_id|     recommendations|\n",
      "+--------+--------------------+\n",
      "|     120|[[16390, 10.48166...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#movie recomendations\n",
    "movieRecs = recommender.recommendForAllItems(10)\n",
    "movieRecs.filter(movieRecs.anime_id==120).show()\n",
    "#This returns the recommender user to watch the anime based on anime_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|anime_id|   recommendations|\n",
      "+--------+------------------+\n",
      "|     120|[16390, 10.481668]|\n",
      "|     120|[66213, 10.460606]|\n",
      "|     120|[29702, 10.435471]|\n",
      "|     120| [5443, 10.416733]|\n",
      "|     120| [5659, 10.359993]|\n",
      "|     120|[59579, 10.358955]|\n",
      "|     120|[54624, 10.353795]|\n",
      "|     120|[59519, 10.343967]|\n",
      "|     120|[54114, 10.334009]|\n",
      "|     120| [8224, 10.307118]|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = movieRecs.filter(movieRecs.anime_id==120)\n",
    "recs = rec.withColumn('recommendations', explode(rec.recommendations))\n",
    "recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = false)\n",
      " |-- recommendations: struct (nullable = true)\n",
      " |    |-- user_id: integer (nullable = true)\n",
      " |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16390, 66213, 29702, 5443, 5659, 59579, 54624, 59519, 54114, 8224]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_users = recs.select(\"anime_id\", 'recommendations.*').select(\"user_id\").rdd.flatMap(lambda x: x).collect()\n",
    "sim_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec_df = recs.toPandas()\n",
    "# rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|    148|[[32400, 9.912419...|\n",
      "|    463|[[32400, 11.00275...|\n",
      "|    471|[[33360, 9.268867...|\n",
      "|    496|[[32400, 11.11616...|\n",
      "|    833|[[32400, 11.15705...|\n",
      "|   1088|[[22607, 12.51817...|\n",
      "|   1238|[[22607, 11.79739...|\n",
      "|   1342|[[4208, 12.100459...|\n",
      "|   1580|[[32400, 11.01759...|\n",
      "|   1591|[[6262, 11.151911...|\n",
      "|   1645|[[22607, 12.63872...|\n",
      "|   1829|[[32400, 10.42426...|\n",
      "|   1959|[[32400, 11.01497...|\n",
      "|   2122|[[22607, 10.69851...|\n",
      "|   2366|[[32400, 9.596404...|\n",
      "|   2659|[[32400, 10.59612...|\n",
      "|   2866|[[32400, 10.95549...|\n",
      "|   3175|[[22607, 12.28804...|\n",
      "|   3749|[[10742, 10.50278...|\n",
      "|   3794|[[32400, 10.59204...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecs = recommender.recommendForAllUsers(10)\n",
    "\n",
    "userRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|  54624|[[22607, 15.26658...|\n",
      "|  16390|[[22607, 15.99666...|\n",
      "|   5659|[[22607, 13.64116...|\n",
      "|  66213|[[3644, 14.618015...|\n",
      "|   5443|[[22607, 14.53432...|\n",
      "|  59579|[[22607, 14.70403...|\n",
      "|  59519|[[22607, 15.09886...|\n",
      "|  54114|[[32894, 15.39254...|\n",
      "|   8224|[[22607, 15.12295...|\n",
      "|  29702|[[22607, 15.83381...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_rec = userRecs.where(userRecs.user_id.isin(sim_users))\n",
    "user_rec.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "|user_id|anime_id|   rating|\n",
      "+-------+--------+---------+\n",
      "|  54624|   22607|15.266581|\n",
      "|  54624|   32894|12.753238|\n",
      "|  54624|    2552|12.662847|\n",
      "|  54624|    3644|12.639414|\n",
      "|  54624|   20969|12.561953|\n",
      "|  54624|    4640|12.509378|\n",
      "|  54624|    5096| 11.65477|\n",
      "|  54624|   32422|11.542713|\n",
      "|  54624|   15159| 11.52776|\n",
      "|  54624|   33911|11.513495|\n",
      "|  16390|   22607|15.996662|\n",
      "|  16390|   29978| 12.42245|\n",
      "|  16390|   17985|12.407199|\n",
      "|  16390|   33360|12.386678|\n",
      "|  16390|    3644|12.364303|\n",
      "|  16390|    1466| 12.20294|\n",
      "|  16390|    3205|12.189185|\n",
      "|  16390|   32894|12.172327|\n",
      "|  16390|    4208|12.092691|\n",
      "|  16390|   21349| 11.85147|\n",
      "+-------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userrecs = user_rec.withColumn('recommendations', explode(user_rec.recommendations))\n",
    "user_picks = userrecs.select(\"user_id\", 'recommendations.*')\n",
    "user_picks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_picks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "userpicks_df = user_picks.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating = userpicks_df.groupby('anime_id').mean()['rating']\n",
    "count_rating = userpicks_df.groupby('anime_id').count()['rating']\n",
    "user_recs_joined = pd.DataFrame([avg_rating,count_rating],columns=avg_rating.index, index=['avg_rating','count_rating']).T\n",
    "user_recs_joined['weighted_avg'] = weighted_rating(user_recs_joined,'count_rating', 'avg_rating')\n",
    "top_anime_recs = user_recs_joined.sort_values('weighted_avg')[:10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title_english</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>33605</td>\n",
       "      <td>Ling Qi</td>\n",
       "      <td>Spiritpact</td>\n",
       "      <td>ONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>5096</td>\n",
       "      <td>Doraemon Movie 28: Nobita To Midori No Kyojin Den</td>\n",
       "      <td>Doraemon The Movie: Nobita And The Green Giant...</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>8677</td>\n",
       "      <td>Sangokushi (1985)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>12163</td>\n",
       "      <td>Ginga Tetsudou 999: Hoshizora Wa Time Machine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>6971</td>\n",
       "      <td>Gegege No Kitarou (1971)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>33360</td>\n",
       "      <td>Code Geass: Boukoku No Akito Final - Itoshiki ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>7729</td>\n",
       "      <td>Hokkyoku No Muushika Miishika</td>\n",
       "      <td>Adventures Of The Polar Cubs</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>32400</td>\n",
       "      <td>Kochinpa!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>16041</td>\n",
       "      <td>Chogattai Majutsu Robot Ginguiser Specials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8485</th>\n",
       "      <td>32422</td>\n",
       "      <td>Doukyuusei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anime_id                                               name  \\\n",
       "1064     33605                                            Ling Qi   \n",
       "1443      5096  Doraemon Movie 28: Nobita To Midori No Kyojin Den   \n",
       "3348      8677                                  Sangokushi (1985)   \n",
       "3434     12163      Ginga Tetsudou 999: Hoshizora Wa Time Machine   \n",
       "3941      6971                           Gegege No Kitarou (1971)   \n",
       "4637     33360  Code Geass: Boukoku No Akito Final - Itoshiki ...   \n",
       "5620      7729                      Hokkyoku No Muushika Miishika   \n",
       "7812     32400                                          Kochinpa!   \n",
       "8365     16041         Chogattai Majutsu Robot Ginguiser Specials   \n",
       "8485     32422                                         Doukyuusei   \n",
       "\n",
       "                                          title_english     type  \n",
       "1064                                         Spiritpact      ONA  \n",
       "1443  Doraemon The Movie: Nobita And The Green Giant...    Movie  \n",
       "3348                                                NaN  Special  \n",
       "3434                                                NaN    Movie  \n",
       "3941                                                NaN       TV  \n",
       "4637                                                NaN  Special  \n",
       "5620                       Adventures Of The Polar Cubs    Movie  \n",
       "7812                                                NaN       TV  \n",
       "8365                                                NaN  Special  \n",
       "8485                                                NaN    Music  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_map[anime_map['anime_id'].isin(top_anime_recs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate recommendations\n",
    "def other_user_recs(anime_id, anime_map):\n",
    "#         movieRecs = self.recommender.recommendForAllItems(10)\n",
    "#         userRecs = self.recommender.recommendForAllUsers(10)\n",
    "        rec = movieRecs.filter(movieRecs.anime_id==anime_id)\n",
    "        recs = rec.withColumn('recommendations', explode(rec.recommendations))\n",
    "        sim_users = recs.select(\"anime_id\", 'recommendations.*').select(\"user_id\").rdd.flatMap(lambda x: x).collect()\n",
    "        user_rec = userRecs.where(userRecs.user_id.isin(sim_users))\n",
    "        userrecs = user_rec.withColumn('recommendations', explode(user_rec.recommendations))\n",
    "        user_picks = userrecs.select(\"user_id\", 'recommendations.*')\n",
    "        userpicks_df = user_picks.toPandas()\n",
    "        avg_rating = userpicks_df.groupby('anime_id').mean()['rating']\n",
    "        count_rating = userpicks_df.groupby('anime_id').count()['rating']\n",
    "        user_recs_joined = pd.DataFrame([avg_rating,count_rating],columns=avg_rating.index, index=['avg_rating','count_rating']).T\n",
    "        user_recs_joined['weighted_avg'] = weighted_rating(user_recs_joined,'count_rating', 'avg_rating')\n",
    "        top_anime_recs = user_recs_joined.sort_values('weighted_avg')[:10].index\n",
    "        return anime_map[anime_map['anime_id'].isin(top_anime_recs)]\n",
    "    \n",
    "def user_rec(user_id, anime_map):\n",
    "    your_rec = userRecs.where(userRecs.user_id==user_id)\n",
    "    yourrecs = your_rec.withColumn('recommendations', explode(your_rec.recommendations))\n",
    "    your_picks = yourrecs.select(\"user_id\", 'recommendations.*').select(\"anime_id\").rdd.flatMap(lambda x: x).collect()\n",
    "    return anime_map[anime_map['anime_id'].isin(your_picks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title_english</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28851</td>\n",
       "      <td>Koe No Katachi</td>\n",
       "      <td>A Silent Voice</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>10471</td>\n",
       "      <td>Ie Naki Ko Remi Specials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>8677</td>\n",
       "      <td>Sangokushi (1985)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685</th>\n",
       "      <td>4640</td>\n",
       "      <td>Maroko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>9558</td>\n",
       "      <td>Cheung Gong Chat Hou</td>\n",
       "      <td>Cj7: The Cartoon</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>7729</td>\n",
       "      <td>Hokkyoku No Muushika Miishika</td>\n",
       "      <td>Adventures Of The Polar Cubs</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8168</th>\n",
       "      <td>6630</td>\n",
       "      <td>Asari-Chan: Ai No Marchen Shoujo</td>\n",
       "      <td>Super Gal Asari: The Dreaming Girl In Fairy World</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>16041</td>\n",
       "      <td>Chogattai Majutsu Robot Ginguiser Specials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>9950</td>\n",
       "      <td>Hulu Xiongdi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>5994</td>\n",
       "      <td>Midoriyama Koukou Koushien-Hen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anime_id                                        name  \\\n",
       "11       28851                              Koe No Katachi   \n",
       "1012     10471                    Ie Naki Ko Remi Specials   \n",
       "3348      8677                           Sangokushi (1985)   \n",
       "4685      4640                                      Maroko   \n",
       "4712      9558                        Cheung Gong Chat Hou   \n",
       "5620      7729               Hokkyoku No Muushika Miishika   \n",
       "8168      6630            Asari-Chan: Ai No Marchen Shoujo   \n",
       "8365     16041  Chogattai Majutsu Robot Ginguiser Specials   \n",
       "8923      9950                                Hulu Xiongdi   \n",
       "9537      5994              Midoriyama Koukou Koushien-Hen   \n",
       "\n",
       "                                          title_english     type  \n",
       "11                                       A Silent Voice    Movie  \n",
       "1012                                                NaN  Special  \n",
       "3348                                                NaN  Special  \n",
       "4685                                                NaN    Movie  \n",
       "4712                                   Cj7: The Cartoon    Movie  \n",
       "5620                       Adventures Of The Polar Cubs    Movie  \n",
       "8168  Super Gal Asari: The Dreaming Girl In Fairy World    Movie  \n",
       "8365                                                NaN  Special  \n",
       "8923                                                NaN       TV  \n",
       "9537                                                NaN      OVA  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_user_recs(7054, anime_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22059, 2881, 30921, 32400, 3327, 820, 29722, 17957, 18029, 7785]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specific recommendations for one user based on user_id:\n",
    "user_id = 5\n",
    "your_rec = userRecs.where(userRecs.user_id==user_id)\n",
    "yourrecs = your_rec.withColumn('recommendations', explode(your_rec.recommendations))\n",
    "your_picks = yourrecs.select(\"user_id\", 'recommendations.*').select(\"anime_id\").rdd.flatMap(lambda x: x).collect()\n",
    "your_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title_english</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>820</td>\n",
       "      <td>Ginga Eiyuu Densetsu</td>\n",
       "      <td>Legend Of The Galactic Heroes</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7785</td>\n",
       "      <td>Yojouhan Shinwa Taikei</td>\n",
       "      <td>The Tatami Galaxy</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>3327</td>\n",
       "      <td>Giant Gorg</td>\n",
       "      <td>Giant Gorg</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>2881</td>\n",
       "      <td>Chinmoku No Kantai</td>\n",
       "      <td>Silent Service</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>29722</td>\n",
       "      <td>Eikoku Ikka, Nihon Wo Taberu</td>\n",
       "      <td>Sushi And Beyond</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7621</th>\n",
       "      <td>22059</td>\n",
       "      <td>Kakumeiteki Broadway Shugisha Doumei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>32400</td>\n",
       "      <td>Kochinpa!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821</th>\n",
       "      <td>17957</td>\n",
       "      <td>Hello Kitty No Papa Nante Daikirai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8830</th>\n",
       "      <td>18029</td>\n",
       "      <td>Hello Kitty No Suteki Na Kyoudai</td>\n",
       "      <td>Hello Kitty In The Wonderful Sisters</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>30921</td>\n",
       "      <td>Kacchikenee!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anime_id                                  name  \\\n",
       "7          820                  Ginga Eiyuu Densetsu   \n",
       "50        7785                Yojouhan Shinwa Taikei   \n",
       "2787      3327                            Giant Gorg   \n",
       "5021      2881                    Chinmoku No Kantai   \n",
       "5514     29722          Eikoku Ikka, Nihon Wo Taberu   \n",
       "7621     22059  Kakumeiteki Broadway Shugisha Doumei   \n",
       "7812     32400                             Kochinpa!   \n",
       "8821     17957    Hello Kitty No Papa Nante Daikirai   \n",
       "8830     18029      Hello Kitty No Suteki Na Kyoudai   \n",
       "9058     30921                          Kacchikenee!   \n",
       "\n",
       "                             title_english   type  \n",
       "7            Legend Of The Galactic Heroes    OVA  \n",
       "50                       The Tatami Galaxy     TV  \n",
       "2787                            Giant Gorg     TV  \n",
       "5021                        Silent Service    OVA  \n",
       "5514                      Sushi And Beyond     TV  \n",
       "7621                                   NaN  Music  \n",
       "7812                                   NaN     TV  \n",
       "8821                                   NaN    OVA  \n",
       "8830  Hello Kitty In The Wonderful Sisters    OVA  \n",
       "9058                                   NaN  Movie  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_map[anime_map['anime_id'].isin(your_picks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>title_english</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>820</td>\n",
       "      <td>Ginga Eiyuu Densetsu</td>\n",
       "      <td>Legend Of The Galactic Heroes</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7785</td>\n",
       "      <td>Yojouhan Shinwa Taikei</td>\n",
       "      <td>The Tatami Galaxy</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>3327</td>\n",
       "      <td>Giant Gorg</td>\n",
       "      <td>Giant Gorg</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>2881</td>\n",
       "      <td>Chinmoku No Kantai</td>\n",
       "      <td>Silent Service</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>29722</td>\n",
       "      <td>Eikoku Ikka, Nihon Wo Taberu</td>\n",
       "      <td>Sushi And Beyond</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7621</th>\n",
       "      <td>22059</td>\n",
       "      <td>Kakumeiteki Broadway Shugisha Doumei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>32400</td>\n",
       "      <td>Kochinpa!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821</th>\n",
       "      <td>17957</td>\n",
       "      <td>Hello Kitty No Papa Nante Daikirai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8830</th>\n",
       "      <td>18029</td>\n",
       "      <td>Hello Kitty No Suteki Na Kyoudai</td>\n",
       "      <td>Hello Kitty In The Wonderful Sisters</td>\n",
       "      <td>OVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>30921</td>\n",
       "      <td>Kacchikenee!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anime_id                                  name  \\\n",
       "7          820                  Ginga Eiyuu Densetsu   \n",
       "50        7785                Yojouhan Shinwa Taikei   \n",
       "2787      3327                            Giant Gorg   \n",
       "5021      2881                    Chinmoku No Kantai   \n",
       "5514     29722          Eikoku Ikka, Nihon Wo Taberu   \n",
       "7621     22059  Kakumeiteki Broadway Shugisha Doumei   \n",
       "7812     32400                             Kochinpa!   \n",
       "8821     17957    Hello Kitty No Papa Nante Daikirai   \n",
       "8830     18029      Hello Kitty No Suteki Na Kyoudai   \n",
       "9058     30921                          Kacchikenee!   \n",
       "\n",
       "                             title_english   type  \n",
       "7            Legend Of The Galactic Heroes    OVA  \n",
       "50                       The Tatami Galaxy     TV  \n",
       "2787                            Giant Gorg     TV  \n",
       "5021                        Silent Service    OVA  \n",
       "5514                      Sushi And Beyond     TV  \n",
       "7621                                   NaN  Music  \n",
       "7812                                   NaN     TV  \n",
       "8821                                   NaN    OVA  \n",
       "8830  Hello Kitty In The Wonderful Sisters    OVA  \n",
       "9058                                   NaN  Movie  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rec(5, anime_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-e85a6ef4c194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatrixFactorizationModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save and load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# recommender.save(\"model/myCollaborativeFilter3\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import mlflow.spark as ml\n",
    "# Save and load model\n",
    "# recommender.save(\"model/myCollaborativeFilter3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.mllib.recommendation.MatrixFactorizationModel.load.\n: org.json4s.package$MappingException: Did not find value which can be converted into java.lang.String\n\tat org.json4s.reflect.package$.fail(package.scala:95)\n\tat org.json4s.Extraction$$anonfun$org$json4s$Extraction$$convert$2.apply(Extraction.scala:704)\n\tat org.json4s.Extraction$$anonfun$org$json4s$Extraction$$convert$2.apply(Extraction.scala:704)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.json4s.Extraction$.org$json4s$Extraction$$convert(Extraction.scala:704)\n\tat org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:394)\n\tat org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:392)\n\tat org.json4s.Extraction$.customOrElse(Extraction.scala:606)\n\tat org.json4s.Extraction$.extract(Extraction.scala:392)\n\tat org.json4s.Extraction$.extract(Extraction.scala:39)\n\tat org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21)\n\tat org.apache.spark.mllib.util.Loader$.loadMetadata(modelSaveLoad.scala:131)\n\tat org.apache.spark.mllib.recommendation.MatrixFactorizationModel$.load(MatrixFactorizationModel.scala:348)\n\tat org.apache.spark.mllib.recommendation.MatrixFactorizationModel.load(MatrixFactorizationModel.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-865668218e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msameModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatrixFactorizationModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model/myCollaborativeFilter2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/mllib/recommendation.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, sc, path)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;34m\"\"\"Load a model from the given path\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMatrixFactorizationModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatrixFactorizationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/mllib/util.py\u001b[0m in \u001b[0;36m_load_java\u001b[0;34m(cls, sc, path)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.mllib.recommendation.MatrixFactorizationModel.load.\n: org.json4s.package$MappingException: Did not find value which can be converted into java.lang.String\n\tat org.json4s.reflect.package$.fail(package.scala:95)\n\tat org.json4s.Extraction$$anonfun$org$json4s$Extraction$$convert$2.apply(Extraction.scala:704)\n\tat org.json4s.Extraction$$anonfun$org$json4s$Extraction$$convert$2.apply(Extraction.scala:704)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.json4s.Extraction$.org$json4s$Extraction$$convert(Extraction.scala:704)\n\tat org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:394)\n\tat org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:392)\n\tat org.json4s.Extraction$.customOrElse(Extraction.scala:606)\n\tat org.json4s.Extraction$.extract(Extraction.scala:392)\n\tat org.json4s.Extraction$.extract(Extraction.scala:39)\n\tat org.json4s.ExtractableJsonAstNode.extract(ExtractableJsonAstNode.scala:21)\n\tat org.apache.spark.mllib.util.Loader$.loadMetadata(modelSaveLoad.scala:131)\n\tat org.apache.spark.mllib.recommendation.MatrixFactorizationModel$.load(MatrixFactorizationModel.scala:348)\n\tat org.apache.spark.mllib.recommendation.MatrixFactorizationModel.load(MatrixFactorizationModel.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "sameModel = MatrixFactorizationModel.load(spark,path=\"model/myCollaborativeFilter2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVDpp, NormalPredictor, Dataset, Reader, accuracy\n",
    "from surprise import KNNBaseline, NMF, SVD\n",
    "from surprise.model_selection import KFold, cross_validate, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "all_data = Dataset.load_from_df(rating_df, reader)\n",
    "train_surprise = Dataset.load_from_df(train, reader)\n",
    "test_surprise = Dataset.load_from_df(test, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(train_surprise):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    preds_surprise = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(preds_surprise, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"say 'Model Complete'\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "for uid, user_ratings in top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
